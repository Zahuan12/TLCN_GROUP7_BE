const db = require("../../models");
const BlogService = require("../../services/blogService"); // âœ… dÃ¹ng láº¡i logic upload trong service

class BlogMediaConsumer {
  constructor(kafka) {
    this.kafka = kafka;
    this.consumer = this.kafka.consumer({ groupId: "blog-media-group" });
    this.topic = process.env.KAFKA_BLOG_MEDIA_TOPIC || "blog-media-events";
  }

  async start() {
    await this.consumer.connect();
    await this.consumer.subscribe({ topic: this.topic, fromBeginning: false });

    await this.consumer.run({
      eachMessage: async ({ topic, partition, message }) => {
        const data = JSON.parse(message.value.toString());
        console.log("[Kafka] ğŸ“¥ Received blog media event:", data.blogMediaId);

        try {
          // âœ… Gá»i sang BlogService Ä‘á»ƒ xá»­ lÃ½ upload vÃ  cáº­p nháº­t DB
          await BlogService.uploadAndUpdateBlogMedia(
            data.blogMediaId,
            data.bufferBase64,
            data.type
          );

          console.log(`[BlogMediaConsumer] âœ… Completed ${data.blogMediaId}`);
        } catch (err) {
          console.error("[BlogMediaConsumer] âŒ Upload error:", err.message);
          await db.BlogMedia.update(
            { status: "error" },
            { where: { id: data.blogMediaId } }
          );
        }
      },
    });

    console.log("[Kafka] ğŸš€ BlogMediaConsumer started and listening...");
  }
}

module.exports = BlogMediaConsumer;
